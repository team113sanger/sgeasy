---
title: "SGE Downstream Analysis Workflow"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{SGE Downstream Analysis Workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

## Introduction

This vignette demonstrates a complete workflow for analyzing Saturation Genome
Editing (SGE) screen data using the sgeasy package. The workflow includes:

1. Reading and preparing count data
2. Joining with sample metadata and variant annotations
3. Filtering and removing artefacts
4. Normalizing using control variants (synonymous/intronic)
5. Running differential abundance analysis with DESeq2
6. Quality control visualization (distance matrices, PCA)
7. Post-processing and statistical adjustment
8. Gene-level analysis
9. Reweighting replicated variants
10. Visualization of results

## Setup

Load the required packages:

```{r libraries, message=FALSE}
library(sgeasy)
library(fs)
library(readr)
library(dplyr)
library(purrr)
library(tidyr)
library(pheatmap)
library(RColorBrewer)
library(ggplot2)
library(glue)
```

## Data Import

### Reading Count Files

SGE count data typically comes from multiple quantification files. Use `fs::dir_ls()`
to find all count files:

```{r find-files}
input_files <- fs::dir_ls(
  "inputs/run_51287",
  type = "any",
  recurse = TRUE,
  glob = "*lib_counts.tsv.gz"
)

# Optionally filter files (e.g., exclude certain samples)
input_files <- input_files[!grepl(input_files, pattern = "pel")]

# Add additional runs if needed
added_files <- fs::dir_ls(
  "inputs/run_47241",
  recurse = TRUE,
  glob = "*lib_counts.tsv.gz"
)
added_files <- added_files[!grepl(added_files, pattern = "mave-qc")]

input_files <- c(input_files, added_files)
```

Read all count files into a single dataset:

```{r read-counts}
counts_dataset <- readr::read_tsv(input_files, comment = "##")
```

### Loading Metadata

Load the screen metadata containing sample information:

```{r load-metadata}
screen_metadata <- readr::read_tsv("metadata/screen_metadata.tsv")

# Calculate duration from condition (e.g., "Day7" -> 7 - 4 = 3)
screen_metadata <- screen_metadata |>
  mutate(duration = as.numeric(str_remove(condition, pattern = "Day")) - 4)
```

## Data Preparation

### Joining Counts with Metadata

Combine count data with sample metadata:

```{r join-metadata}
complete_dataset <- counts_dataset |>
  left_join(screen_metadata, by = c("SAMPLE" = "sequencing_id"))
```

### Sample Exclusion

Remove any problematic samples:

```{r exclude-samples}
exclude_samples <- c("SAMPLE_A_10_pel0000")  # Replace with actual sample names

complete_dataset <- complete_dataset |>
  dplyr::filter(!supplier_name %in% exclude_samples) |>
  dplyr::filter(!SAMPLE %in% exclude_samples) |>
  dplyr::filter(targeton_id != "FRTW")  # Exclude specific targetons if needed
```

### Splitting by Targeton

If your data contains multiple targetons, split into separate datasets:

```{r split-targeton}
targeton_matrices <- complete_dataset |>
  group_by(targeton_id) |>
  group_split()

# Name each list element by targeton_id
targeton_matrices <- targeton_matrices |>
  purrr::set_names(map_chr(targeton_matrices, ~ unique(.x$targeton_id)))
```

### Creating Count Matrices

Pivot the data to wide format with samples as columns. **Important:** Use
`names_prefix = "count_"` to prepend a prefix to sample column names:

```{r pivot-wide}
count_matrices <- map(
  targeton_matrices,
  pivot_wider,
  names_from = "supplier_name",
  values_from = "COUNT",
  names_prefix = "count_",
  id_cols = c("NAME", "SEQUENCE", "LENGTH", "targeton_id")
)
```

Handle duplicate sequences by keeping the first occurrence:

```{r deduplicate}
unique_matrices <- map(
  count_matrices,
  ~ group_by(.x, SEQUENCE) |>
    slice_head(n = 1) |>
    ungroup()
)
```

### Filtering by Count Threshold

Use `filter_by_counts()` to remove low-count variants:

```{r filter-counts}
filtered_matrices <- map(
  unique_matrices,
  filter_by_counts,
  min_counts = 10
)
```

## Adding Variant Annotations

Load VEP annotations and join with count data:

```{r load-annotations}
# Get annotation file path from metadata
annotations <- screen_metadata |>
  pull(vep_anno) |>
  unique()

master_annotation <- readr::read_tsv(annotations)

# Join annotations
annotated_counts <- map(
  filtered_matrices,
  ~ left_join(
    .x,
    master_annotation,
    by = c("SEQUENCE" = "Seq", "targeton_id" = "Targeton_ID")
  )
)
```

### Removing Artefacts

Remove variants that lack valid sgRNA identifiers (artefacts):

```{r remove-artefacts}
annotated_counts <- map(annotated_counts, remove_artefacts)
```

## Normalization

### Creating Normalization Matrices

Extract neutral variants (synonymous and intronic) for normalization:

```{r norm-matrix}
normalisation_matrices <- map(
  annotated_counts,
  create_normalization_matrix
)
```

This uses variants with no expected functional effect as controls for
estimating library size factors.

### Creating Input Matrices

Create the full count matrices for analysis:

```{r input-matrix}
complete_matrices <- map(
  annotated_counts,
  create_count_matrix
)
```

## Differential Abundance Analysis

Run the complete differential abundance pipeline:

```{r run-analysis}
deseq_results <- map2(
  complete_matrices,
  normalisation_matrices,
  run_differential_analysis,
  sample_metadata = screen_metadata
)
```

The `run_differential_analysis()` function:

1. Estimates size factors from control variants
2. Creates a DESeq2 dataset with the experimental design
3. Applies control-derived normalization
4. Runs Wald tests for all condition contrasts
5. Computes regularized log transformation
6. Generates z-scores for visualization
7. Runs continuous analysis for rate estimation

### Combining Results

Combine contrast tables from all targetons using `map_dfr` with `.id` to
preserve targeton identity:

```{r combine-results}
contrast_tables <- map_dfr(
  deseq_results,
  pluck, "contrast_summary",
  .id = "Targeton_ID"
)
```

## Quality Control Visualization

### Sample Distance Matrices

Visualize sample-to-sample distances to check for outliers and batch effects:

```{r distance-matrices}
rlog_results <- map(deseq_results, pluck, "rlog")

dist_matrices <- map(rlog_results, sample_distance_matrix)
plot_distance_matrices(dist_matrices, output_dir = "results/qc")
```

### PCA Plots

Create PCA plots to visualize sample clustering:

```{r pca-plots}
screen_pcas <- map(rlog_results, build_sample_pca)
plot_screen_pcas(screen_pcas, output_dir = "results/qc")
```

## Post-Processing

Apply post-processing to combine results with annotations, recalculate
statistics, and classify variants:

```{r post-process}
recalculated_contrast_tables <- post_process(
  data = contrast_tables,
  annotation = master_annotation
)
```

The `post_process()` function:

1. Joins with the annotation file by SEQUENCE and Targeton_ID
2. Calculates median log2FoldChange from neutral variants
3. Adjusts all contrasts by subtracting medians and computing z-scores
4. Classifies variants as depleted/enriched/unchanged based on FDR
5. Simplifies consequence annotations

## Visualization

### Waterfall Plots by Targeton

Generate waterfall plots for each targeton and condition:

```{r waterfall-plots}
individual_screens <- recalculated_contrast_tables |>
  group_by(Targeton_ID) |>
  group_split() |>
  set_names(unique(recalculated_contrast_tables$Targeton_ID))

plot_sets <- imap(
  individual_screens,
  ~ plot_all_conditions(.x, .y)
)

write_waterfall_plots(plot_sets, output_dir = "results/screen")
```

## Gene-Level Analysis

For multi-exon genes, combine results across targetons:

### Adding Exon Annotations

```{r exon-annotations}
exon_annotations <- recalculated_contrast_tables |>
  dplyr::select(Targeton_ID, EXON) |>
  group_by(Targeton_ID) |>
  slice_head(n = 1) |>
  mutate(Exons = as.numeric(str_remove(EXON, pattern = "/6"))) |>
  arrange(desc(Exons)) |>
  dplyr::select(Targeton_ID, Exons) |>
  ungroup() |>
  mutate(Exons = factor(Exons, levels = c("6", "5", "4", "3", "2", "1")))

gene_level_dataset <- recalculated_contrast_tables |>
  left_join(exon_annotations, by = "Targeton_ID")
```

### Gene-Level Plot

Create a gene-level functional score plot faceted by exon:

```{r gene-level-plot}
score_col <- "adj_lfc_continuous"
class_col <- "functional_classification_continuous"
fdr_col <- "FDR_continuous"
gene_id <- "MYGENE"

gene_level <- ggplot(gene_level_dataset, aes(
  x = vcf_pos,
  y = .data[[score_col]],
  shape = .data[[class_col]],
  colour = slim_consequence,
  fill = slim_consequence
)) +
  geom_point(aes(alpha = .data[[fdr_col]] <= 0.01), size = 1.5) +
  scale_colour_manual(values = consequence_colours) +
  scale_fill_manual(values = consequence_colours) +
  scale_shape_manual(values = classification_shapes) +
  scale_alpha_discrete(labels = c("FDR > 0.01", "FDR <= 0.01")) +
  xlab("GRCh38 coordinate") +
  ylab("Functional score (Adjusted LFC)") +
  ggtitle(paste("Functional score Plot:", gene_id)) +
  theme_classic() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1,
                               colour = "black", size = 10),
    legend.title = element_blank(),
    legend.position = "right",
    legend.box = "vertical",
    legend.margin = margin()
  ) +
  facet_wrap(~ Exons, scales = "free_x", nrow = 1)

ggsave("results/gene_level_plot.png", gene_level,
       width = 25, height = 6, units = "in", dpi = 300)
```

## Reweighting Replicated Variants

Some variants may be represented by multiple oligos. Use inverse variance
weighting to combine these measurements:

### Preparing Results for Reweighting

```{r prep-reweight}
results <- gene_level_dataset |>
  select(Targeton_ID, SEQUENCE, HGVSc, HGVSp, pam_mut_sgrna_id,
         contains("continuous"))
```

### Finding Replicated Variants

```{r find-replicates}
replicated_variants <- get_replicated_variants(results)
replicated_variants
```

### Applying Inverse Variance Weighting

```{r reweight}
reweighted_variants <- reweight_replicated_variants(results)
```

The reweighting strategy:

- Non-PAM observations receive weight = 1/SE^2
- PAM-impacted observations receive zero weight if non-PAM alternatives exist
- PAM-only variants use normal weighting (better than nothing)

### Comparing Classifications

Check how reweighting affects classifications:

```{r compare-classifications}
reweighted_variants |>
  select(HGVSc, HGVSp, functional_classification) |>
  left_join(results, by = c("HGVSc", "HGVSp")) |>
  select(HGVSc, HGVSp, functional_classification,
         functional_classification_continuous) |>
  filter(functional_classification != functional_classification_continuous)
```

### Weighted Score Plot

```{r weighted-plot}
combined_dataset <- reweighted_variants |>
  left_join(gene_level_dataset, by = c("HGVSc", "HGVSp"))

weighted_scores <- ggplot(combined_dataset, aes(
  x = vcf_pos,
  y = combined_lfc,
  shape = functional_classification,
  colour = slim_consequence,
  fill = slim_consequence
)) +
  geom_point(aes(alpha = FDR <= 0.01), size = 1.5) +
  scale_colour_manual(values = consequence_colours) +
  scale_fill_manual(values = consequence_colours) +
  scale_shape_manual(values = classification_shapes) +
  scale_alpha_discrete(labels = c("FDR > 0.01", "FDR <= 0.01")) +
  xlab("GRCh38 coordinate") +
  ylab("Functional score (Weighted LFC)") +
  ggtitle(paste("Functional score Plot:", gene_id, "- Weighted LFC")) +
  theme_classic() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1,
                               colour = "black", size = 10),
    legend.title = element_blank(),
    legend.position = "right",
    legend.box = "vertical",
    legend.margin = margin()
  ) +
  facet_wrap(~ Exons, scales = "free_x", nrow = 1)

ggsave("results/gene_level_plot_reweight.png", weighted_scores,
       width = 25, height = 6, units = "in", dpi = 300)
```

## Exporting Results

Save the final results:

```{r export}
# Gene-level weighted scores
combined_dataset |>
  select(HGVSc, HGVSp, combined_lfc, functional_classification, FDR) |>
  left_join(results, by = c("HGVSc", "HGVSp")) |>
  write_tsv("results/gene_level_weighted_scores.tsv")
```

## Session Info

```{r session-info}
sessionInfo()
```
